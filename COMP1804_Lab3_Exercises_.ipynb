{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP1804 Lab3 Exercises .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ade1986/testrepository/blob/master/COMP1804_Lab3_Exercises_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_dkYxebD9DJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "___\n",
        "# COMP1804 Lab2.03 - Python Exercises (Collecting and Visualising Twitter Data)\n",
        "---\n",
        ".                                                                                                                                                                                  \n",
        "\n",
        "We are now going beyond Python Basics to experiment with the various Python libraries for handling data. Yes, we're jumping in the deep end here! and this is a good strategy to build on the basics coverd and learn along the way.\n",
        "\n",
        "In this lab, you will learn how to collect Twitter data and you will use the simple String manipulation techniques covered last week as well as the pandas library to compare the popularity of given words. You will also learn how to use the pyplot library to plot simple graphs. \n",
        "\n",
        "Social media gives organisations and businesses an unprecedented opportunity for connecting with the people and customers, and identifying relevant prospects. Analysing online text data is frequently used for opion mining, sentiment analysis, understanding followers, analysing the reach and results of poles or posts, identifying influencers, improving ROI (return on investment), and much more. \n",
        "\n",
        "**In this lab we will be using the Twitter Streaming API to download tweets related to the following keyword: \"Brexit\". By the end of this lab, you should be able to collect Twitter data using Python, do simple analysis, plot small graphs and export the data as csv/txt file.**\n",
        "\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wllE-t99JVvG",
        "colab_type": "text"
      },
      "source": [
        "#1 Colleting Twitter Data using the Twitter Streaming API\n",
        "Twitter provides a number of APIs to developers in order to access data programmaticlly. In this lab we will be using the Twitter Streaming API to download tweets related to the following 3 keywords: \"Brexit\", \"Leave\", and \"Remain\". Twitter also provides a REST API for the same purpose - you can find out more on this [here](https://developer.twitter.com/en.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FK7hYJeRK6c",
        "colab_type": "text"
      },
      "source": [
        "##a) The Twitter Streaming API requires: an API key, API secret, Access Token and Access Token Secret\n",
        "> To get your keys and tokens, complete the following (detailed instructions in [COMP1804_Lab3_SupportingMaterial-Twitter](https://moodlecurrent.gre.ac.uk/pluginfile.php/1188895/mod_resource/content/4/COMP1804-1819-Lab3%20SupportingMaterial-Twitter.pdf)):\n",
        "\n",
        "1.   Create a Twitter account at https://twitter.com/signup, if you do not already have one.\n",
        "2.   To collect Twitter data you need to create Twitter app. Go to https://apps.twitter.com/ and log in with your Twitter credentials.\n",
        "3.   Click \"Create New App\".\n",
        "4.   Fill out the form, agree to the terms, and click \"Create your Twitter application\".\n",
        "5.   In the next page, click on \"API keys\" tab, and copy your \"API key\" and \"API secret\".\n",
        "6.   Scroll down and click \"Create my access token\", and copy your \"Access token\" and \"Access token secret\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vQ7HBeyNP0",
        "colab_type": "text"
      },
      "source": [
        "Steps 5 and 6 generate your credentials which are needed for accessing the Twitter APIs. They are used in the Python code below to connect to the Twitter Streaming API. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Q0JWWNhW1T",
        "colab_type": "text"
      },
      "source": [
        "##b) Connecting to the Twitter Streaming API and downloading data\n",
        "The Python Tweepy module is needed to connect to Twitter Streaming API and for downloading the data. [Tweepy](https://github.com/tweepy/tweepy) is an open-source module, hosted on GitHub, that provides a set of simple methods to communicate with the Twitter platform and use its API. \n",
        "\n",
        "If Tweepy is not already installed in your PyCharm, follow the installation instructions in [COMP1804_Lab3_SupportingMaterial-tweepy](https://moodlecurrent.gre.ac.uk/pluginfile.php/1167723/course/section/674707/COMP1804-1819-Lab3%20SupportingMaterial-Tweepy.pdf).\n",
        "\n",
        "The code below streams . Make sure you replace the values access_token, access_token_secret, consumer_key, and consumer_secret with the credentials generated in steps 5 and 6 above.\n",
        "\n",
        "When you run the code, you will see data streamed in the box below. To interrupt the streaming click the stop icon on the left (Ctl+M)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V7PtpORDFrv1",
        "colab": {}
      },
      "source": [
        "#Import the necessary methods from tweepy library\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "\n",
        "\n",
        "#Variables that contains the user credentials to access Twitter API \n",
        "consumer_key = \"ENTER YOUR API KEY                              #API Key\n",
        "consumer_secret = \"ENTER YOUR API SECRET\"  #API Secret \n",
        "access_token = \"ENTER YOUR ACCESS TOKEN\"     #Access Token\n",
        "access_token_secret = \"ENTER YOUR TOKEN SECRET\"   #Token Secret\n",
        "\n",
        "\n",
        "#This is a basic listener that just prints received tweets to stdout.\n",
        "class Listener(StreamListener):\n",
        "    \n",
        "    # override method from tweepy.streaming\n",
        "    def on_data(self, data):\n",
        "        print(data)\n",
        "        brexitFile = open('BrexitTweets.txt','a')\n",
        "        brexitFile.write(data)\n",
        "        brexitFile.close()       \n",
        "      \n",
        "    #def on_status(self, status):\n",
        "    #    print(status.text)  \n",
        "        \n",
        "    def on_error(self, status_code):\n",
        "        if status_code == 420:\n",
        "            return False\n",
        "\n",
        "\n",
        "#Handles Twitter authetinication and the connection to Twitter Streaming API\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "stream = Stream(auth, Listener())\n",
        "\n",
        "#Filter Twitter Streams to capture data by keywords: 'brexit', 'leave', 'remain'\n",
        "stream.filter(track=['brexit'])\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g39XHPpUZFYZ",
        "colab_type": "text"
      },
      "source": [
        "##c) Reading collected data from file\n",
        "\n",
        "\n",
        "The Twitter Streaming API returns tweets in JSON format. JSON stands for JavaScript Object Notation. This format makes the data easily readable both my humans and machines. Open the tweet file generated in the previous step and note the additional information it contains apart from the main tweet text. The following map of twitter message details by Raffi Krikorian, 2010 illustrates the JSON notation used and the corresponding meaning. More detail and up-to-date information on tweet format and the additional information tweets contain can be found on the [twitter developer's website](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeEqZ4fRdSNl",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/cocoxu/socialmedia-class.github.io/master/assets/img/raffi-krikorian-map-of-a-tweet.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBhncerad-lw",
        "colab_type": "text"
      },
      "source": [
        "###Following is an example of using the Python json or simplejson modules to read in the tweet data in JSON format and process them in a more readable format. \n",
        "The code demonstrates of how to read and process a subset of the tweet details. Other data in JSON format can be processed in a similar way.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGPfSzPuZeB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the necessary package to process data in JSON format\n",
        "try:\n",
        "    import json\n",
        "except ImportError:\n",
        "    import simplejson as json\n",
        "\n",
        "# Read in the file saved from last step \n",
        "tweets_filename = 'BrexitTweets.txt'\n",
        "tweets_file = open(tweets_filename, \"r\")\n",
        "\n",
        "# Tidy up the tweets so they're easier to read\n",
        "for line in tweets_file:\n",
        "    try:\n",
        "        # Read in one line of the file, convert it into a json object \n",
        "        tweet = json.loads(line.strip())\n",
        "        if 'text' in tweet:                # only messages containing a 'text' field are displayed\n",
        "            print(tweet['id'])                  # the tweet's id\n",
        "            print(tweet['created_at'])          # when the tweet was posted\n",
        "            print(tweet['text'])                # content of the tweet\n",
        "                        \n",
        "            print(tweet['user']['id'])          # id of the user who posted the tweet\n",
        "            print(tweet['user']['name'])        # name of the user\n",
        "            print(tweet['user']['screen_name']) # name of the user account\n",
        "\n",
        "            hashtags = []\n",
        "            for hashtag in tweet['entities']['hashtags']:\n",
        "                hashtags.append(hashtag['text'])\n",
        "            print(hashtags)\n",
        "\n",
        "    except:\n",
        "        # if line read is not in JSON format, an exception may be thrown (we'll ignore here)\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF8EVtdTzKZB",
        "colab_type": "text"
      },
      "source": [
        "#2 Analysing and  visualising collected Twitter data\n",
        "For this we'll use the pandas module for data manipulation, matplotlib for plotting charts, and re for regular expressions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFNkXCHn0InP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAjHBSKA0Zs0",
        "colab_type": "text"
      },
      "source": [
        "We will read in the data from BrexitTweets.txt in into a list called bTweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV24QVgP1soX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the file saved from last step \n",
        "tweets_filename = 'BrexitTweets.txt'\n",
        "tweets_file = open(tweets_filename, \"r\")\n",
        "\n",
        "brexitTweets = []\n",
        "for line in tweets_file:\n",
        "    try:\n",
        "        brexitTweets.append(json.loads(line))\n",
        "    except:\n",
        "        continue\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0PYpE012z3a",
        "colab_type": "text"
      },
      "source": [
        "We can then use the list.len method to find out how many tweets we collected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxA5aYgX3KkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(brexitTweets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfKXe1tg3-nZ",
        "colab_type": "text"
      },
      "source": [
        "pandas can be used to structure tweets data into a pandas DataFrame to simplify the data manipulation. DataFrames are a 2-dimensional, size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). \n",
        "\n",
        "Here, we'll create a  tweetsDF with three columns text, lang, and country. The 'text' column contains the main tweet text, the lang column contains the language in which the tweet was written, and country is the country from which the tweet was sent.\n",
        "\n",
        "We first create an empty tweetsDF. Then the map() function is used to applies the lambda function of extracting the given key to each JSON element of brexitTweets list and assiagns a list of the results to each column on the tweetsDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c671JNYZJmt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweetsDF = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWv36MhtJzDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweetsDF['text'] = list(map(lambda tweet: tweet['text'], brexitTweets))\n",
        "tweetsDF['lang'] = list(map(lambda tweet: tweet['lang'], brexitTweets))\n",
        "tweetsDF['country'] = list(map(lambda tweet: tweet['place']['country'] if tweet['place'] != None else None, brexitTweets))\n",
        "tweetsDF.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ-rpeHXmkvB",
        "colab_type": "text"
      },
      "source": [
        "Now we've got the tweets in a better managable data structure, it's easy to use pyplot from matplotlib to plot charts.\n",
        "The following code looks for the top 5 languages the tweets were written in and displays a bar chart.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUBTXDQzJ2np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_by_lang = tweetsDF['lang'].value_counts()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.tick_params(axis='x', labelsize=15)\n",
        "ax.tick_params(axis='y', labelsize=10)\n",
        "ax.set_xlabel('Languages', fontsize=15)\n",
        "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
        "ax.set_title('Top 5 languages', fontsize=15, fontweight='bold')\n",
        "tweets_by_lang[:5].plot(ax=ax, kind='bar', color='green')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISwE4x82nvpT",
        "colab_type": "text"
      },
      "source": [
        "This code illustrates the top 5 countries where the tweets were written"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBDMfK3eoBij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_by_country = tweetsDF['country'].value_counts()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.tick_params(axis='x', labelsize=15)\n",
        "ax.tick_params(axis='y', labelsize=10)\n",
        "ax.set_xlabel('Countries', fontsize=15)\n",
        "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
        "ax.set_title('Top 5 countries', fontsize=15, fontweight='bold')\n",
        "tweets_by_country[:5].plot(ax=ax, kind='bar', color='grey')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTic75N4tCv1",
        "colab_type": "text"
      },
      "source": [
        "Same results displayed in a pie chart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oII33FSEtJjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_by_country = tweetsDF['country'].value_counts()\n",
        "tweets_by_country[:5].plot(kind='pie', label='Top 5 Countries')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j40_QSRmqFww",
        "colab_type": "text"
      },
      "source": [
        "#3 Activity\n",
        "Once you've completed this notebook, experiment with the same code in PyCharm. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5OWfO8mxAdr",
        "colab_type": "text"
      },
      "source": [
        "In your PyCharm project create a file called Lab3_TwitterStreaming.py. Remember to make sure you replace all strings starting with \"ENTER YOUR...\" with your own twitter credentials into access_token, access_token_secret, consumer_key, and consumer_secret."
      ]
    }
  ]
}